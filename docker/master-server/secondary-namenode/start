#!/bin/bash

set -o errexit
set -o pipefail
set -o nounset


# echo "Starting Hadoop secondary name node..."
# hdfs --daemon start secondarynamenode

mkdir -p /opt/hadoop/dfs/name

# ${NAMEDIR}에 파일이 있는 지 확인
if [ -z $(ls -A ${NAMEDIR}) ]; then
  echo "Formatting namenode name directory: ${NAMEDIR}"

  # 네임노드 디렉터리를 포맷 (초기화)
  hdfs namenode -format
fi

echo "Starting Hadoop name node..."

# 세컨더리 네임노드 start
echo "Starting Hadoop secondary name node..."
hdfs --daemon start secondarynamenode

echo "Starting Hadoop resource manager..."
yarn --daemon start resourcemanager

if [ ! -f "${NAMEDIR}"/initialized ]; then
  echo "Configuring Hive..."
  hdfs dfs -mkdir -p  /user/hive/warehouse
  schematool -dbType postgres -initSchema --verbose
  touch "${NAMEDIR}"/initialized
fi

echo "Starting Hive Metastore..."
hive --service metastore &

echo "Starting Hive server2..."
hiveserver2 &

if ! hdfs dfs -test -d /tmp
then
  echo "Formatting directory: /tmp"
  hdfs dfs -mkdir -p  /tmp
fi
if ! hdfs dfs -test -d "${SPARK_LOGS_HDFS_PATH}"
then
  echo "Formatting directory: ${SPARK_LOGS_HDFS_PATH}"
  hdfs dfs -mkdir -p  "${SPARK_LOGS_HDFS_PATH}"
fi
if ! hdfs dfs -test -d "${SPARK_JARS_HDFS_PATH}"
then
  echo "Formatting directory: ${SPARK_JARS_HDFS_PATH}"
  hdfs dfs -mkdir -p  "${SPARK_JARS_HDFS_PATH}"
  hdfs dfs -put "$SPARK_HOME"/jars/* "${SPARK_JARS_HDFS_PATH}"/
fi

echo "Starting Spark master node..."
spark-class org.apache.spark.deploy.master.Master --ip "${SPARK_MASTER_HOST}"
